--- 
title: Home 
layout: default 
---


<h1>Introduction to RLPark</h1>

RLPark is a Java framework to do reinforcement learning with robots. RLPark uses
<a href="http://thomasdegris.github.com/Zephyr">Zephyr</a>
for visualization and real-time display. It is also compatible with the Eclipse RCP framework.



<h4>RLPark features and algorithms:</h4>
<ul>
	<li>Sarsa, Expected Sarsa, Q-Learning</li>
	<li>Actor-Critic with normal distribution (continuous actions) and Boltzmann distribution (discrete action),
		average reward actor-critic<br>
	</li>
	<li>TD, TD(λ), GTD(λ), GQ(λ), TDC</li>
	<li>Acting: softmax, greedy, ε-greedy<br>
	</li>
	<li>Representations: tile coding (with no hashing, hashing and hashing with mumur2), Linear Threshold Unit,
		observation history, feature normalization<br>
	</li>
	<li>Robots: the <a href="https://sites.google.com/a/rl-community.org/critterbot/hardware/the-critterbot-robot">Critterbot</a>,
		<a href="https://sites.google.com/a/rl-community.org/critterbot/hardware/the-irobot-create">iRobot Create</a></li>
	<li>Compatible with <a href="http://thomasdegris.github.com/Zephyr">Zephyr</a></li>
	<li>Problems: mountain car, swing-up pendulum, random walk</li>
	<li>Eligibility traces: accumulating traces, accumulating traces with a max, replacing traces</li>
</ul>
<ul>

</ul>
